import json
import re
import os
import requests
import time
import random
from urllib.parse import urlparse

def get_deep_domains(api_url):
    """
    é€šè¿‡ä¸‰æ¬¡å¸¦æœ‰éšæœºå‚æ•°çš„è¯·æ±‚ï¼Œæ¨¡æ‹Ÿå¤šè·¯å¾„å—…æ¢ï¼Œæ•è·åŠ¨æ€ CDN åŸŸå
    """
    found_domains = set()
    found_keywords = set()
    
    for i in range(3):
        try:
            timestamp = int(time.time())
            nonce = random.randint(100, 999)
            target_url = f"{api_url}?ac=detail&pg=1&_t={timestamp}&_n={nonce}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            
            resp = requests.get(target_url, headers=headers, timeout=15)
            if resp.status_code == 200:
                data = resp.json()
                vod_list = data.get('list', [])
                for vod in vod_list:
                    play_url = vod.get('vod_play_url', '')
                    urls = re.findall(r'https?://[^\$,\s]+', play_url)
                    for u in urls:
                        domain = urlparse(u).netloc.split(':')[0]
                        if domain and len(domain) > 3:
                            found_domains.add(domain)
                            
                            # --- ğŸ§  é€»è¾‘ 1ï¼šæå–å‰ç¼€è¯æ ¹ (å¦‚ v12.qewbn.com -> v) ---
                            parts = domain.split('.')
                            if len(parts) >= 3:
                                prefix = parts[0]
                                if re.match(r'^[a-z]{1,4}\d+$', prefix):
                                    keyword = re.sub(r'\d+', '', prefix)
                                    if len(keyword) >= 2:
                                        found_keywords.add(keyword)

                            # --- ğŸ§  é€»è¾‘ 2ï¼šæå–ä¸»åŸŸæ ¸å¿ƒ (å¦‚ wwzycdn.10cong.com -> 10cong) ---
                            # å¢åŠ è¿™ä¸ªé€»è¾‘æ¥å¯¹ä»˜å¢ƒå¤–é‡‡é›†ç«™
                            if len(parts) >= 2:
                                main_name = parts[-2] # æ‹¿åˆ°å€’æ•°ç¬¬äºŒä¸ªå…ƒç´ 
                                # å¦‚æœä¸»åŸŸåæ˜¯è¿™ç§ä¹±ç æˆ–ç‰¹å®šä»£å·ï¼ŒæŠ“ä¸‹æ¥
                                if len(main_name) > 4: 
                                    found_keywords.add(main_name)
            
            time.sleep(0.5) # ç¨å¾®ç¼©çŸ­é—´æ­‡ï¼Œæé€Ÿ
        except Exception as e:
            print(f"      âš ï¸ ç¬¬ {i+1} æ¬¡å°è¯•å¤±è´¥: {e}")
            
    return found_domains, found_keywords

def generate():
    base_path = os.path.dirname(os.path.abspath(__file__))
    json_path = os.path.join(base_path, 'db.json')
    
    if not os.path.exists(json_path):
        print("âŒ æ‰¾ä¸åˆ° db.json æ–‡ä»¶")
        return

    with open(json_path, 'r', encoding='utf-8') as f:
        db = json.load(f)

    all_domains = set()
    
    # --- ğŸŸ¢ é‡ç‚¹ï¼šæ‰‹åŠ¨æ‰©å……é¢„è®¾è¯åº“ï¼Œæ‹¦æˆªå·²çŸ¥å¢ƒå¤–é‡‡é›†ç«™ ---
    all_keywords = {
        "m3u8", "index.m3u8", "yyv", "cdnlz", "yzzy", 
        "wwzy", "10cong", "bfzy", "jszy", "hhzy", "ffzy"
    } 

    print(f"ğŸš€ å¼€å§‹æ·±åº¦æ‰«æ {len(db.get('sites', []))} ä¸ªé‡‡é›†ç«™ API...")
    
    for site in db.get('sites', []):
        api = site.get('api', '')
        if not api or not api.startswith('http'): continue
            
        print(f"ğŸ” æ­£åœ¨æ¢æµ‹: {site.get('name', 'æœªçŸ¥ç«™')}")
        
        api_host = urlparse(api).netloc.split(':')[0]
        if api_host: all_domains.add(api_host)
        
        domains, keywords = get_deep_domains(api)
        all_domains.update(domains)
        all_keywords.update(keywords)

    with open('MyVideo.list', 'w', encoding='utf-8') as f:
        f.write("# ----------------------------------------------------------\n")
        f.write(f"# 2026 è‡ªåŠ¨ç”Ÿæˆç²¾ç¡®ç›´è¿è§„åˆ™ (å¢ƒå¤–é‡‡é›†ç«™å¢å¼ºç‰ˆ)\n")
        f.write(f"# æ›´æ–°æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("# ----------------------------------------------------------\n\n")
        
        f.write("# [å…³é”®è¯è¡¥æ¼ - åº”å¯¹å¢ƒå¤–ä¹±ç åŸŸå]\n")
        for kw in sorted(list(all_keywords)):
            # è¿‡æ»¤æ‰å¤ªçŸ­æˆ–å¤ªé€šç”¨çš„è¯ï¼Œé˜²æ­¢è¯¯æ€
            if kw and kw not in ["com", "net", "org", "www"]:
                f.write(f"DOMAIN-KEYWORD,{kw}\n")
        
        f.write("\n# [ç²¾ç¡®åŸŸååŒ¹é…]\n")
        for d in sorted(list(all_domains)):
            if d: f.write(f"DOMAIN-SUFFIX,{d}\n")
            
    print(f"âœ… ç”Ÿæˆå®Œæ¯•ï¼æ•è·åŸŸå: {len(all_domains)}ï¼Œæå–è¯æ ¹: {len(all_keywords)}")

if __name__ == "__main__":
    generate()
# --- æ ¸å¿ƒä¿®æ­£ï¼šå†™å…¥ç¬¦åˆ Clash Classic (YAML) æ ¼å¼çš„æ–‡ä»¶ ---
    with open('MyVideo.list', 'w', encoding='utf-8') as f:
        # 1. å¿…é¡»æœ‰ payload å¤´éƒ¨
        f.write("payload:\n")
        
        # 2. å†™å…¥å…³é”®è¯è§„åˆ™ï¼ˆå¿…é¡»æœ‰ 2 ä¸ªç©ºæ ¼ç¼©è¿›å’Œæ ç¬¦å·ï¼‰
        print("âœï¸ æ­£åœ¨å†™å…¥å…³é”®è¯è§„åˆ™...")
        for kw in sorted(list(all_keywords)):
            if kw and kw not in ["com", "net", "org", "www", "cdn"]:
                f.write(f"  - DOMAIN-KEYWORD,{kw}\n")
        
        # 3. å†™å…¥åç¼€è§„åˆ™ï¼ˆå¿…é¡»æœ‰ 2 ä¸ªç©ºæ ¼ç¼©è¿›å’Œæ ç¬¦å·ï¼‰
        print("âœï¸ æ­£åœ¨å†™å…¥åŸŸååç¼€è§„åˆ™...")
        for d in sorted(list(all_domains)):
            if d:
                f.write(f"  - DOMAIN-SUFFIX,{d}\n")
            
    print(f"âœ… è½¬æ¢å®Œæ¯•ï¼æ–‡ä»¶å·²é€‚é… clash-classic æ ¼å¼ã€‚")
